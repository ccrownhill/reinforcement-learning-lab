{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('FrozenLake-v1', is_slippery=False)\n",
    "slippery_env = gym.make('FrozenLake-v1', is_slippery=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`epsilon`: with this probability you do a random action  \n",
    "`1 - epsilon`: with this probability you do the best action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_game(env, policy, epsilon):\n",
    "    done = False\n",
    "    sar_list = []\n",
    "    state = env.reset()\n",
    "    \n",
    "    while not done:\n",
    "        if np.random.random() < epsilon:\n",
    "            action = np.random.choice(env.action_space.n)\n",
    "        else:\n",
    "            action = policy[state]\n",
    "            \n",
    "        new_state, reward, done, _ = env.step(action)\n",
    "        \n",
    "        sar_list.append([state, action, reward])\n",
    "        state = new_state\n",
    "    \n",
    "    return sar_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_control(env, epochs, epsilon=0.25):\n",
    "    num_states = env.observation_space.n\n",
    "    num_actions = env.action_space.n\n",
    "    Q = np.zeros((num_states,num_actions))\n",
    "    returns = {(s,a): [] for s in range(num_states) for a in range(num_actions)}\n",
    "    policy = np.random.choice(num_actions,size=num_states)\n",
    "    r_list = []\n",
    "    \n",
    "    for ep in range(epochs): # training episodes\n",
    "        # generate episode using policy\n",
    "        sar_list = play_game(env, policy, epsilon)\n",
    "        \n",
    "        # adjust policy accordingly\n",
    "        reward_sum = 0\n",
    "        for state, action, reward in reversed(sar_list):\n",
    "            reward_sum += reward\n",
    "            returns[(state, action)].append(reward_sum)\n",
    "            Q[state, action] = np.mean(returns[(state, action)])\n",
    "            if max(Q[state]) > 0:\n",
    "                policy[state] = np.argmax(Q[state])\n",
    "        \n",
    "        r_list.append(reward_sum)\n",
    "        if (ep+1) % int(epochs/10) == 0:\n",
    "            print(f\"Epoch {ep+1}, Mean reward: {np.mean(r_list)}\")\n",
    "            r_list = []\n",
    "    \n",
    "    return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000, Mean reward: 0.533\n",
      "Epoch 2000, Mean reward: 0.726\n",
      "Epoch 3000, Mean reward: 0.751\n",
      "Epoch 4000, Mean reward: 0.708\n",
      "Epoch 5000, Mean reward: 0.729\n",
      "Epoch 6000, Mean reward: 0.726\n",
      "Epoch 7000, Mean reward: 0.742\n",
      "Epoch 8000, Mean reward: 0.722\n",
      "Epoch 9000, Mean reward: 0.733\n",
      "Epoch 10000, Mean reward: 0.72\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1, 3, 1, 0, 2, 2, 1, 3, 0, 2, 2, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = mc_control(env, 10000, epsilon=0.25)\n",
    "policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000, Mean reward: 0.09\n",
      "Epoch 2000, Mean reward: 0.114\n",
      "Epoch 3000, Mean reward: 0.111\n",
      "Epoch 4000, Mean reward: 0.12\n",
      "Epoch 5000, Mean reward: 0.159\n",
      "Epoch 6000, Mean reward: 0.26\n",
      "Epoch 7000, Mean reward: 0.305\n",
      "Epoch 8000, Mean reward: 0.315\n",
      "Epoch 9000, Mean reward: 0.308\n",
      "Epoch 10000, Mean reward: 0.316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 3, 0, 0, 0, 0, 2, 3, 3, 1, 0, 0, 2, 2, 1, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slippery_policy = mc_control(slippery_env, 10000, epsilon=0.15)\n",
    "slippery_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_policy(policy, env):\n",
    "    done = False\n",
    "    state = env.reset()\n",
    "    while not done:\n",
    "        state, reward, done, _ = env.step(policy[state])\n",
    "        env.render()\n",
    "\n",
    "    if reward:\n",
    "        print(\"Reached GOAL!!!\")\n",
    "    else:\n",
    "        print(\"Fell into hole ):\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Down)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "F\u001b[41mF\u001b[0mFH\n",
      "HFFG\n",
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "FF\u001b[41mF\u001b[0mH\n",
      "HFFG\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HF\u001b[41mF\u001b[0mG\n",
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFF\u001b[41mG\u001b[0m\n",
      "Reached GOAL!!!\n"
     ]
    }
   ],
   "source": [
    "test_policy(policy, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "SFFF\n",
      "FHFH\n",
      "F\u001b[41mF\u001b[0mFH\n",
      "HFFG\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "H\u001b[41mF\u001b[0mFG\n",
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HF\u001b[41mF\u001b[0mG\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HF\u001b[41mF\u001b[0mG\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HF\u001b[41mF\u001b[0mG\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFF\u001b[41mG\u001b[0m\n",
      "Reached GOAL!!!\n"
     ]
    }
   ],
   "source": [
    "test_policy(slippery_policy, slippery_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
